{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append('/coc/scratch/anarayanan68/mint/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: To use the exr data format, please install the OpenEXR package following the instructions detailed in the README at github.com/tensorflow/graphics.\n",
      "Warning: To use the threejs_vizualization, please install the colabtools package following the instructions detailed in the README at github.com/tensorflow/graphics.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, initializers, regularizers\n",
    "\n",
    "from mint.core import fact_model, base_model_util, base_models, primitive_models\n",
    "from mint.utils import inputs_util, config_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlendController(keras.Model):\n",
    "    def __init__(self, num_primitives, cond_vocab_size, config_dict, name=\"BlendController\", **kwargs):\n",
    "        super(BlendController, self).__init__(name=name, **kwargs)\n",
    "\n",
    "        self.num_primitives = num_primitives\n",
    "        \n",
    "        transformer_config_yaml = config_dict['transformer']\n",
    "        self.audio_linear_embedding = base_models.LinearEmbedding(\n",
    "            transformer_config_yaml['hidden_size'])\n",
    "        self.audio_pos_embedding = base_models.PositionEmbedding(\n",
    "            transformer_config_yaml['sequence_length'],\n",
    "            transformer_config_yaml['hidden_size'])\n",
    "        self.transformer = base_models.Transformer(\n",
    "            hidden_size=transformer_config_yaml['hidden_size'],\n",
    "            num_hidden_layers=transformer_config_yaml['num_hidden_layers'],\n",
    "            num_attention_heads=transformer_config_yaml['num_attention_heads'],\n",
    "            intermediate_size=transformer_config_yaml['intermediate_size']\n",
    "        )\n",
    "\n",
    "        initializer = initializers.RandomNormal()   # so that, hopefully, each embedding is different from the start\n",
    "        self.conditioning_block = layers.Embedding(cond_vocab_size, transformer_config_yaml['hidden_size'],\n",
    "            input_length=1, embeddings_initializer=initializer, embeddings_regularizer=None, name='cond_input_embedding')\n",
    "\n",
    "        output_block_config_yaml = config_dict['output_block']\n",
    "        self.output_block = keras.Sequential([\n",
    "            layers.GlobalAveragePooling1D(),\n",
    "            base_models.MLP(out_dim=num_primitives, hidden_dim=output_block_config_yaml['hidden_dim']),\n",
    "            layers.Softmax()\n",
    "        ])\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        audio_seq = inputs['audio_input']                               # (batch_size, seq_len, audio_feature_dim)\n",
    "        audio_features = self.audio_linear_embedding(audio_seq)         # (batch_size, seq_len, transformer_hidden_size)\n",
    "        audio_features = self.audio_pos_embedding(audio_features)       # (batch_size, seq_len, transformer_hidden_size)\n",
    "        audio_features = self.transformer(audio_features)               # (batch_size, seq_len, transformer_hidden_size)\n",
    "\n",
    "        conditioning = inputs['conditioning_input']                     # (batch_size, conditioning_input_dim)\n",
    "        conditioning_features = self.conditioning_block(conditioning)   # (batch_size, 1, transformer_hidden_size)\n",
    "\n",
    "        combined_features = audio_features + conditioning_features      # (batch_size, seq_len, transformer_hidden_size)\n",
    "        out_vec = self.output_block(combined_features)                  # (batch_size, num_primitives)\n",
    "        return out_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_primitives': 100,\n",
       " 'conditioning_dim': 1,\n",
       " 'conditioning_vocab_size': 10,\n",
       " 'audio_to_blend_vec': {'transformer': {'sequence_length': 60,\n",
       "   'hidden_size': 256,\n",
       "   'num_hidden_layers': 1,\n",
       "   'num_attention_heads': 8,\n",
       "   'intermediate_size': 1024},\n",
       "  'output_block': {'hidden_dim': 256}},\n",
       " 'blend_vec_to_seq': {'target_shape': '120,147'}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_config_yaml_path = '/coc/scratch/anarayanan68/mint/configs/audio_based_blending__embed_based_conditioning-enc_config.yml'\n",
    "enc_config_yaml = config_util.read_yaml_config(enc_config_yaml_path)\n",
    "\n",
    "enc_config_yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2b = BlendController(\n",
    "    num_primitives=enc_config_yaml['num_primitives'],\n",
    "    cond_vocab_size=enc_config_yaml['conditioning_vocab_size'],\n",
    "    config_dict=enc_config_yaml['audio_to_blend_vec']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 100), dtype=float32, numpy=\n",
       "array([[0.01170535, 0.01079346, 0.00968513, 0.01035765, 0.00944266,\n",
       "        0.01025323, 0.00821733, 0.01215233, 0.00861848, 0.01071779,\n",
       "        0.0118113 , 0.0087884 , 0.00981206, 0.01228856, 0.00941273,\n",
       "        0.0096304 , 0.01045018, 0.00959557, 0.00934233, 0.00923613,\n",
       "        0.00847851, 0.00967992, 0.00929915, 0.00890301, 0.00842417,\n",
       "        0.00981407, 0.01289271, 0.00912185, 0.00999935, 0.01246821,\n",
       "        0.00742049, 0.01167622, 0.00959626, 0.00694625, 0.00841384,\n",
       "        0.00995899, 0.01132338, 0.00792442, 0.01104884, 0.01151963,\n",
       "        0.0122895 , 0.01073207, 0.00873414, 0.00938094, 0.00847098,\n",
       "        0.01282649, 0.00891778, 0.00905286, 0.01034872, 0.00996136,\n",
       "        0.00849223, 0.01116323, 0.01140295, 0.00972154, 0.01341921,\n",
       "        0.00828702, 0.00961407, 0.00973543, 0.00942487, 0.00945527,\n",
       "        0.00925506, 0.00908624, 0.01231977, 0.01080496, 0.00917186,\n",
       "        0.0095695 , 0.0099464 , 0.00814201, 0.01108983, 0.01125926,\n",
       "        0.01023948, 0.01022008, 0.00908337, 0.01141278, 0.01111008,\n",
       "        0.00880466, 0.01138081, 0.01223952, 0.0096716 , 0.00788353,\n",
       "        0.0088495 , 0.01272327, 0.01214008, 0.00786328, 0.00824971,\n",
       "        0.00867447, 0.01353988, 0.00863192, 0.00968504, 0.01043847,\n",
       "        0.00941042, 0.00955843, 0.00901435, 0.01109791, 0.0087224 ,\n",
       "        0.00857188, 0.01098683, 0.01092732, 0.00919118, 0.01038187],\n",
       "       [0.00939007, 0.01107264, 0.00829061, 0.01092308, 0.00762424,\n",
       "        0.01109632, 0.00959933, 0.0095718 , 0.00926448, 0.00881897,\n",
       "        0.01326067, 0.00943092, 0.00990511, 0.01080754, 0.00987416,\n",
       "        0.00891409, 0.00958014, 0.00930778, 0.01048094, 0.00955997,\n",
       "        0.00973545, 0.01026214, 0.00808402, 0.00865718, 0.00772131,\n",
       "        0.0088838 , 0.01076625, 0.00745399, 0.00971655, 0.01089112,\n",
       "        0.00916907, 0.01342546, 0.00978983, 0.00562355, 0.0089232 ,\n",
       "        0.01144921, 0.01229015, 0.00958145, 0.01184412, 0.0091902 ,\n",
       "        0.01417499, 0.00943213, 0.00798017, 0.00906517, 0.01218686,\n",
       "        0.00984024, 0.01055115, 0.0105598 , 0.01235178, 0.0102292 ,\n",
       "        0.00873547, 0.00871896, 0.0101493 , 0.01045029, 0.01230435,\n",
       "        0.01093684, 0.01291525, 0.00980217, 0.00896004, 0.00944098,\n",
       "        0.00745394, 0.00852931, 0.01271922, 0.01054552, 0.010663  ,\n",
       "        0.00994588, 0.0101508 , 0.00869748, 0.00960372, 0.0134082 ,\n",
       "        0.00743655, 0.01040139, 0.01024436, 0.01078771, 0.00911133,\n",
       "        0.00822156, 0.0106187 , 0.0116764 , 0.01096015, 0.01105143,\n",
       "        0.0103952 , 0.01053763, 0.01117714, 0.00911572, 0.00725593,\n",
       "        0.01062779, 0.01362043, 0.00908163, 0.01040467, 0.00964303,\n",
       "        0.00944401, 0.01138067, 0.01004668, 0.00860506, 0.00766448,\n",
       "        0.00920256, 0.01201166, 0.00933251, 0.01010224, 0.00910819],\n",
       "       [0.01026597, 0.0109238 , 0.01058555, 0.01031703, 0.00790054,\n",
       "        0.00914647, 0.01043327, 0.00961429, 0.0098156 , 0.00994479,\n",
       "        0.00903885, 0.00959057, 0.00760436, 0.01050505, 0.00923815,\n",
       "        0.00885262, 0.01189946, 0.01068745, 0.01111477, 0.00917947,\n",
       "        0.00740708, 0.00987537, 0.00842218, 0.01023799, 0.0084014 ,\n",
       "        0.00765807, 0.00959537, 0.00823373, 0.00940057, 0.01037676,\n",
       "        0.00987976, 0.01164657, 0.00952718, 0.007893  , 0.01057503,\n",
       "        0.01185335, 0.01262499, 0.00810777, 0.00925734, 0.00932771,\n",
       "        0.01196414, 0.01060327, 0.01099276, 0.01047913, 0.01231403,\n",
       "        0.01112655, 0.0087264 , 0.0108567 , 0.01120426, 0.00999404,\n",
       "        0.01101189, 0.00940067, 0.01069854, 0.01037817, 0.01419092,\n",
       "        0.01042034, 0.01038967, 0.00971631, 0.00937228, 0.00832189,\n",
       "        0.00799165, 0.00810731, 0.01215122, 0.00839755, 0.00846091,\n",
       "        0.00972009, 0.00992967, 0.00845958, 0.0091268 , 0.01275936,\n",
       "        0.00886255, 0.00989205, 0.01058598, 0.01180615, 0.01062538,\n",
       "        0.00670743, 0.01013926, 0.01253614, 0.01129924, 0.00905867,\n",
       "        0.00976507, 0.01145527, 0.01205801, 0.00771856, 0.00928905,\n",
       "        0.01182754, 0.01275077, 0.01001074, 0.00927965, 0.00976853,\n",
       "        0.00965939, 0.01063893, 0.01007438, 0.00802369, 0.00825327,\n",
       "        0.00913653, 0.01122827, 0.01111153, 0.01233866, 0.00987391],\n",
       "       [0.0118527 , 0.01093594, 0.00831049, 0.01041703, 0.01030294,\n",
       "        0.00896951, 0.0081032 , 0.01225008, 0.00842124, 0.00992578,\n",
       "        0.0126705 , 0.00934228, 0.00835183, 0.01206438, 0.00734061,\n",
       "        0.01245117, 0.01145746, 0.00935635, 0.01027213, 0.00939205,\n",
       "        0.00819154, 0.00966786, 0.00698761, 0.01079937, 0.00874066,\n",
       "        0.00774322, 0.01045682, 0.00802837, 0.00833943, 0.01017051,\n",
       "        0.00861262, 0.01256675, 0.00798711, 0.00690191, 0.01071595,\n",
       "        0.01161269, 0.01056227, 0.0094432 , 0.01138886, 0.01000019,\n",
       "        0.01299439, 0.0102937 , 0.01003419, 0.00879136, 0.00899722,\n",
       "        0.01174516, 0.00801573, 0.0081268 , 0.01112793, 0.00999924,\n",
       "        0.00927431, 0.00902814, 0.01082784, 0.01054791, 0.01400877,\n",
       "        0.0082978 , 0.01045562, 0.01000118, 0.01305958, 0.00792706,\n",
       "        0.0082181 , 0.00844468, 0.01255647, 0.01083078, 0.01102105,\n",
       "        0.01132107, 0.01214914, 0.00859683, 0.0101154 , 0.01255552,\n",
       "        0.01031907, 0.01102163, 0.01013375, 0.01209563, 0.00700069,\n",
       "        0.00799335, 0.01218663, 0.01162979, 0.00853597, 0.00917788,\n",
       "        0.00840455, 0.01139018, 0.01154415, 0.00883197, 0.00751262,\n",
       "        0.01126702, 0.0128415 , 0.01142089, 0.00887594, 0.01204738,\n",
       "        0.00928008, 0.01071019, 0.00895485, 0.00927251, 0.00774594,\n",
       "        0.00993361, 0.01061465, 0.00941081, 0.00944788, 0.0099313 ],\n",
       "       [0.01103373, 0.01158118, 0.01021318, 0.01097086, 0.00900159,\n",
       "        0.00888048, 0.01020082, 0.00926819, 0.0102274 , 0.00974439,\n",
       "        0.01005192, 0.0088486 , 0.00958643, 0.01188883, 0.00944985,\n",
       "        0.01012939, 0.0096722 , 0.01038939, 0.01197768, 0.01023501,\n",
       "        0.00809941, 0.00947014, 0.00820449, 0.01029908, 0.00903852,\n",
       "        0.00940396, 0.00892111, 0.00798287, 0.01032247, 0.0105009 ,\n",
       "        0.00800768, 0.00976019, 0.01098018, 0.00890033, 0.01026454,\n",
       "        0.01122237, 0.01012045, 0.00869406, 0.01035422, 0.00908313,\n",
       "        0.01324161, 0.00989292, 0.01066903, 0.01013689, 0.00790046,\n",
       "        0.0104267 , 0.00994875, 0.0077147 , 0.01213275, 0.01251904,\n",
       "        0.00998869, 0.00839148, 0.01206173, 0.00988479, 0.01440686,\n",
       "        0.00986936, 0.01020239, 0.01074558, 0.00903367, 0.00961849,\n",
       "        0.00791557, 0.00787475, 0.0134833 , 0.01127125, 0.008814  ,\n",
       "        0.01117609, 0.00925364, 0.00865083, 0.00702059, 0.01165607,\n",
       "        0.01048739, 0.01047725, 0.00783827, 0.01016838, 0.01005456,\n",
       "        0.00702398, 0.00822072, 0.01089655, 0.01162303, 0.00844885,\n",
       "        0.01016006, 0.01151437, 0.01265285, 0.00909204, 0.00889669,\n",
       "        0.01260611, 0.01441904, 0.00917389, 0.01166235, 0.01079791,\n",
       "        0.00881106, 0.01276801, 0.00764474, 0.00891946, 0.00779103,\n",
       "        0.0096982 , 0.01019408, 0.0100712 , 0.0097519 , 0.00925278],\n",
       "       [0.01146956, 0.01281323, 0.01035306, 0.01051718, 0.00805096,\n",
       "        0.00945618, 0.01054873, 0.00831774, 0.01037231, 0.00908731,\n",
       "        0.00994646, 0.00839655, 0.01015141, 0.01003668, 0.01116428,\n",
       "        0.01012166, 0.01065825, 0.00944781, 0.01120546, 0.00983283,\n",
       "        0.00925188, 0.01043788, 0.00911981, 0.00887945, 0.00892692,\n",
       "        0.01224486, 0.01036983, 0.0076085 , 0.01184241, 0.0098255 ,\n",
       "        0.01012613, 0.0110085 , 0.0118351 , 0.00720908, 0.00947061,\n",
       "        0.0100246 , 0.00889336, 0.00955668, 0.01081627, 0.00943265,\n",
       "        0.01244673, 0.00927458, 0.01017432, 0.00991243, 0.00949746,\n",
       "        0.01168191, 0.01058143, 0.0090323 , 0.01112822, 0.01156152,\n",
       "        0.00908804, 0.00984487, 0.01053346, 0.01030931, 0.0120527 ,\n",
       "        0.01046775, 0.01171737, 0.01094373, 0.00844891, 0.01127947,\n",
       "        0.00702341, 0.00832498, 0.01193583, 0.00890396, 0.00820628,\n",
       "        0.01071796, 0.01095905, 0.00929456, 0.00873694, 0.01205141,\n",
       "        0.01169299, 0.0082833 , 0.00860377, 0.01022984, 0.01207777,\n",
       "        0.00700853, 0.00665795, 0.01215451, 0.01098335, 0.00934714,\n",
       "        0.00984154, 0.01169023, 0.01033928, 0.00888312, 0.00877533,\n",
       "        0.01241409, 0.01090916, 0.00796358, 0.01129214, 0.0111016 ,\n",
       "        0.01005076, 0.01037063, 0.00836311, 0.007888  , 0.00723872,\n",
       "        0.00884336, 0.00905876, 0.00963576, 0.01368886, 0.00965434],\n",
       "       [0.00963632, 0.010152  , 0.0079098 , 0.01034297, 0.01045261,\n",
       "        0.0110046 , 0.00677733, 0.01029417, 0.01076679, 0.00979409,\n",
       "        0.01016621, 0.01132924, 0.01000608, 0.01002817, 0.008227  ,\n",
       "        0.01050992, 0.00979216, 0.00986702, 0.01062122, 0.01068623,\n",
       "        0.01055405, 0.00981559, 0.00775667, 0.00764496, 0.01014445,\n",
       "        0.01099393, 0.01322972, 0.00970381, 0.00970577, 0.01186383,\n",
       "        0.00812829, 0.01116291, 0.0083163 , 0.00667856, 0.00888366,\n",
       "        0.0111235 , 0.00987614, 0.01132806, 0.01133049, 0.01023295,\n",
       "        0.01529062, 0.0086734 , 0.01012359, 0.00981674, 0.01014164,\n",
       "        0.01058004, 0.00937137, 0.01006081, 0.01215686, 0.01117784,\n",
       "        0.00872012, 0.00992529, 0.01002276, 0.00951584, 0.01034256,\n",
       "        0.0093099 , 0.00993738, 0.01093297, 0.00833418, 0.0083199 ,\n",
       "        0.00834182, 0.00796133, 0.00927673, 0.00959224, 0.00900565,\n",
       "        0.01069797, 0.01029909, 0.00963289, 0.00769057, 0.01024928,\n",
       "        0.01034684, 0.00861763, 0.01004135, 0.00913087, 0.01048939,\n",
       "        0.01086607, 0.01211858, 0.01233934, 0.00890039, 0.01020003,\n",
       "        0.00980354, 0.01183133, 0.0111754 , 0.01213236, 0.00843626,\n",
       "        0.01101734, 0.01292945, 0.00938223, 0.00967029, 0.01107153,\n",
       "        0.01021093, 0.01049586, 0.01011224, 0.00967539, 0.00951335,\n",
       "        0.00845365, 0.01085598, 0.01080818, 0.00789926, 0.00913605],\n",
       "       [0.01073233, 0.01165728, 0.00999013, 0.01061132, 0.00907266,\n",
       "        0.0092512 , 0.00906327, 0.00949426, 0.0097364 , 0.0097475 ,\n",
       "        0.00976169, 0.00928505, 0.01010315, 0.0108072 , 0.00811727,\n",
       "        0.00976936, 0.00858768, 0.01009764, 0.00964288, 0.01010222,\n",
       "        0.01222426, 0.01039015, 0.00889041, 0.01025246, 0.0084914 ,\n",
       "        0.00938456, 0.01231636, 0.00921878, 0.00968448, 0.0122472 ,\n",
       "        0.00779182, 0.01138154, 0.00900981, 0.00650123, 0.0087786 ,\n",
       "        0.01117289, 0.0119115 , 0.0098505 , 0.01215037, 0.00937782,\n",
       "        0.01413232, 0.0089832 , 0.01114886, 0.01092795, 0.01088344,\n",
       "        0.01096362, 0.01102559, 0.00789031, 0.01171589, 0.00936319,\n",
       "        0.00917916, 0.0100914 , 0.00970145, 0.00929233, 0.01262574,\n",
       "        0.01041342, 0.0110299 , 0.01100521, 0.00911409, 0.00891909,\n",
       "        0.0066171 , 0.0070351 , 0.01262877, 0.00879456, 0.00867949,\n",
       "        0.0099243 , 0.0121438 , 0.00920754, 0.00826241, 0.01185717,\n",
       "        0.00832569, 0.00897685, 0.0106066 , 0.01175762, 0.0097144 ,\n",
       "        0.01030786, 0.00972207, 0.01338587, 0.01016862, 0.00901628,\n",
       "        0.01086999, 0.01101752, 0.01046627, 0.00867253, 0.008937  ,\n",
       "        0.01052381, 0.01611807, 0.0093609 , 0.01056439, 0.00741909,\n",
       "        0.00786329, 0.01038164, 0.01010854, 0.00957893, 0.00827361,\n",
       "        0.00945796, 0.01217033, 0.0096961 , 0.00917383, 0.0071513 ],\n",
       "       [0.01092126, 0.01204391, 0.00997637, 0.01164224, 0.00823309,\n",
       "        0.00941617, 0.00882592, 0.00945506, 0.01149834, 0.01041286,\n",
       "        0.00947124, 0.00992244, 0.00949376, 0.01265585, 0.01004147,\n",
       "        0.00908782, 0.01038859, 0.00960939, 0.00970083, 0.00896383,\n",
       "        0.008506  , 0.00938111, 0.00919561, 0.00940269, 0.00815181,\n",
       "        0.00888663, 0.01091304, 0.00829163, 0.0106581 , 0.01055678,\n",
       "        0.00974349, 0.01144047, 0.0091549 , 0.00836415, 0.0092861 ,\n",
       "        0.01067575, 0.01175987, 0.008359  , 0.00887835, 0.01024692,\n",
       "        0.01550781, 0.00982037, 0.00993443, 0.00797186, 0.01066308,\n",
       "        0.01198437, 0.0083123 , 0.00938625, 0.01073573, 0.01118254,\n",
       "        0.00842966, 0.00872349, 0.01163818, 0.01004308, 0.01520224,\n",
       "        0.00864328, 0.0110527 , 0.01081459, 0.00918891, 0.00940729,\n",
       "        0.00839931, 0.0089046 , 0.01306995, 0.00914865, 0.0079067 ,\n",
       "        0.00912251, 0.00963675, 0.00878925, 0.01015897, 0.01177556,\n",
       "        0.00967705, 0.00910246, 0.00851138, 0.00987253, 0.01175393,\n",
       "        0.00804727, 0.01078372, 0.01357524, 0.01238862, 0.00861185,\n",
       "        0.01027234, 0.01089196, 0.01230445, 0.00872024, 0.00813616,\n",
       "        0.01057928, 0.01200808, 0.00987808, 0.01037801, 0.01053605,\n",
       "        0.00905783, 0.0096502 , 0.00859587, 0.0100045 , 0.00799076,\n",
       "        0.00796877, 0.01090457, 0.01078788, 0.00958329, 0.01026032],\n",
       "       [0.01095998, 0.01016602, 0.00844986, 0.01032207, 0.00873621,\n",
       "        0.01054655, 0.00934902, 0.00946735, 0.01023059, 0.01025754,\n",
       "        0.0115933 , 0.00973491, 0.00915418, 0.01027102, 0.00960486,\n",
       "        0.01092095, 0.0121673 , 0.00947698, 0.01132387, 0.00975793,\n",
       "        0.00782161, 0.01055572, 0.00761123, 0.00751669, 0.00769337,\n",
       "        0.01025004, 0.01078773, 0.00815705, 0.01195283, 0.00992641,\n",
       "        0.00919455, 0.01201506, 0.01137595, 0.00652765, 0.00973688,\n",
       "        0.01265931, 0.00934883, 0.00993243, 0.01043697, 0.00944044,\n",
       "        0.01330416, 0.00833807, 0.00828401, 0.00956196, 0.0096094 ,\n",
       "        0.0113478 , 0.00945189, 0.01056078, 0.01059723, 0.01138289,\n",
       "        0.00783436, 0.00829187, 0.01130279, 0.01180252, 0.01186975,\n",
       "        0.00880281, 0.01294503, 0.01039803, 0.01009851, 0.00932297,\n",
       "        0.00725504, 0.00792649, 0.01247227, 0.01026783, 0.01044086,\n",
       "        0.01081146, 0.00915215, 0.00922465, 0.0105035 , 0.01075347,\n",
       "        0.00971199, 0.01001086, 0.00853738, 0.00959456, 0.01058069,\n",
       "        0.00745717, 0.00986618, 0.01242084, 0.01129487, 0.01050595,\n",
       "        0.01080959, 0.01132818, 0.01168865, 0.00978108, 0.00729431,\n",
       "        0.01120432, 0.01188232, 0.00920276, 0.01050313, 0.01051231,\n",
       "        0.0106028 , 0.01049275, 0.00813171, 0.00848395, 0.00711946,\n",
       "        0.00963253, 0.01034052, 0.00932247, 0.01137466, 0.01096611]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_audios = np.random.randn(10,60,35)\n",
    "test_cond = np.arange(10).reshape((-1,1))\n",
    "\n",
    "test_ins = {\n",
    "    'audio_input': test_audios,\n",
    "    'conditioning_input': test_cond\n",
    "}\n",
    "test_outs = a2b(test_ins)\n",
    "\n",
    "test_outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 120, 147), dtype=float32, numpy=\n",
       "array([[[0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        ...,\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923]],\n",
       "\n",
       "       [[0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        ...,\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923]],\n",
       "\n",
       "       [[0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        ...,\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        ...,\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923]],\n",
       "\n",
       "       [[0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        ...,\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923]],\n",
       "\n",
       "       [[0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        ...,\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923]]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2s = primitive_models.BlendVecToSeq(\n",
    "    num_primitives=enc_config_yaml['num_primitives'],\n",
    "    config_dict=enc_config_yaml['blend_vec_to_seq']\n",
    ")\n",
    "\n",
    "test_seq_outs = b2s(test_outs)\n",
    "test_seq_outs"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "73ef9dae1850d4826a6a2abacc613ceaa38b06453232522e74b0afa9475d9130"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('ai-choreo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
