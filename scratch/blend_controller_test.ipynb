{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append('/coc/scratch/anarayanan68/mint/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: To use the exr data format, please install the OpenEXR package following the instructions detailed in the README at github.com/tensorflow/graphics.\n",
      "Warning: To use the threejs_vizualization, please install the colabtools package following the instructions detailed in the README at github.com/tensorflow/graphics.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, initializers, regularizers\n",
    "\n",
    "from mint.core import fact_model, base_model_util, base_models, primitive_models\n",
    "from mint.utils import inputs_util, config_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlendController(keras.Model):\n",
    "    def __init__(self, num_primitives, config_dict, name=\"BlendController\", **kwargs):\n",
    "        super(BlendController, self).__init__(name=name, **kwargs)\n",
    "\n",
    "        self.num_primitives = num_primitives\n",
    "        \n",
    "        transformer_config_yaml = config_dict['transformer']\n",
    "        self.audio_linear_embedding = base_models.LinearEmbedding(\n",
    "            transformer_config_yaml['hidden_size'])\n",
    "        self.audio_pos_embedding = base_models.PositionEmbedding(\n",
    "            transformer_config_yaml['sequence_length'],\n",
    "            transformer_config_yaml['hidden_size'])\n",
    "        self.transformer = base_models.Transformer(\n",
    "            hidden_size=transformer_config_yaml['hidden_size'],\n",
    "            num_hidden_layers=transformer_config_yaml['num_hidden_layers'],\n",
    "            num_attention_heads=transformer_config_yaml['num_attention_heads'],\n",
    "            intermediate_size=transformer_config_yaml['intermediate_size']\n",
    "        )\n",
    "        self.conditioning_block = base_models.LinearEmbedding(\n",
    "            transformer_config_yaml['hidden_size'])\n",
    "\n",
    "        output_block_config_yaml = config_dict['output_block']\n",
    "        self.output_block = keras.Sequential([\n",
    "            layers.GlobalAveragePooling1D(),\n",
    "            base_models.MLP(out_dim=num_primitives, hidden_dim=output_block_config_yaml['hidden_dim']),\n",
    "            layers.Softmax()\n",
    "        ])\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        audio_seq = inputs['audio_input']                               # (batch_size, seq_len, audio_feature_dim)\n",
    "        audio_features = self.audio_linear_embedding(audio_seq)         # (batch_size, seq_len, transformer_hidden_size)\n",
    "        audio_features = self.audio_pos_embedding(audio_features)       # (batch_size, seq_len, transformer_hidden_size)\n",
    "        audio_features = self.transformer(audio_features)               # (batch_size, seq_len, transformer_hidden_size)\n",
    "\n",
    "        conditioning = inputs['conditioning_input']                     # (batch_size, conditioning_input_dim)\n",
    "        conditioning_features = self.conditioning_block(conditioning)   # (batch_size, transformer_hidden_size)\n",
    "        conditioning_features = tf.expand_dims(conditioning_features, axis=1)   # (batch_size, 1, transformer_hidden_size) for broadcasting\n",
    "\n",
    "        combined_features = audio_features + conditioning_features      # (batch_size, seq_len, transformer_hidden_size)\n",
    "        out_vec = self.output_block(combined_features)                  # (batch_size, num_primitives)\n",
    "        return out_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_primitives': 4,\n",
       " 'audio_to_blend_vec': {'transformer': {'sequence_length': 60,\n",
       "   'hidden_size': 256,\n",
       "   'num_hidden_layers': 1,\n",
       "   'num_attention_heads': 8,\n",
       "   'intermediate_size': 1024},\n",
       "  'output_block': {'hidden_dim': 256}},\n",
       " 'blend_vec_to_seq': {'target_shape': '120,147'}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_config_yaml_path = '/coc/scratch/anarayanan68/mint/configs/audio_based_blending__pilot-enc_config.yml'\n",
    "enc_config_yaml = config_util.read_yaml_config(enc_config_yaml_path)\n",
    "\n",
    "enc_config_yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2b = BlendController(\n",
    "    num_primitives=enc_config_yaml['num_primitives'],\n",
    "    config_dict=enc_config_yaml['audio_to_blend_vec']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 4), dtype=float32, numpy=\n",
       "array([[0.2872154 , 0.2312548 , 0.2329574 , 0.2485724 ],\n",
       "       [0.26555488, 0.24848545, 0.26498887, 0.22097085],\n",
       "       [0.26632044, 0.25842467, 0.30879375, 0.1664612 ],\n",
       "       [0.33855763, 0.17743748, 0.28232503, 0.20167986],\n",
       "       [0.2971854 , 0.22945176, 0.257187  , 0.21617585],\n",
       "       [0.27057102, 0.17500177, 0.28820422, 0.26622298],\n",
       "       [0.30671242, 0.22543874, 0.2509774 , 0.21687144],\n",
       "       [0.33105534, 0.23257144, 0.19516602, 0.24120717]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_audios = np.random.randn(8,60,35)\n",
    "test_cond = np.random.randn(8,2)\n",
    "\n",
    "test_ins = {\n",
    "    'audio_input': test_audios,\n",
    "    'conditioning_input': test_cond\n",
    "}\n",
    "test_outs = a2b(test_ins)\n",
    "\n",
    "test_outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 120, 147), dtype=float32, numpy=\n",
       "array([[[0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        ...,\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923]],\n",
       "\n",
       "       [[0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        ...,\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923]],\n",
       "\n",
       "       [[0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        ...,\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        ...,\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923]],\n",
       "\n",
       "       [[0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        ...,\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923]],\n",
       "\n",
       "       [[0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        ...,\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923],\n",
       "        [0.00752923, 0.00752923, 0.00752923, ..., 0.00752923,\n",
       "         0.00752923, 0.00752923]]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2s = primitive_models.BlendVecToSeq(\n",
    "    num_primitives=enc_config_yaml['num_primitives'],\n",
    "    config_dict=enc_config_yaml['blend_vec_to_seq']\n",
    ")\n",
    "\n",
    "test_seq_outs = b2s(test_outs)\n",
    "test_seq_outs"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "73ef9dae1850d4826a6a2abacc613ceaa38b06453232522e74b0afa9475d9130"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('ai-choreo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
