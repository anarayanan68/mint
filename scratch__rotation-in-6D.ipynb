{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from aist_plusplus.loader import AISTDataset\n",
    "\n",
    "from tools import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_dir = \"/srv/share/datasets/AIST/aist_plusplus_final/\"\n",
    "subset_size = 20\n",
    "\n",
    "dataset = AISTDataset(anno_dir)\n",
    "\n",
    "seq_names = []\n",
    "seq_names += np.loadtxt(\n",
    "    os.path.join(anno_dir, \"splits/crossmodal_train.txt\"), dtype=str\n",
    ").tolist()\n",
    "seq_names += np.loadtxt(\n",
    "    os.path.join(anno_dir, \"splits/crossmodal_val.txt\"), dtype=str\n",
    ").tolist()\n",
    "seq_names += np.loadtxt(\n",
    "    os.path.join(anno_dir, \"splits/crossmodal_test.txt\"), dtype=str\n",
    ").tolist()\n",
    "ignore_list = np.loadtxt(\n",
    "    os.path.join(anno_dir, \"ignore_list.txt\"), dtype=str\n",
    ").tolist()\n",
    "seq_names = [name for name in seq_names if name not in ignore_list]\n",
    "seq_names = seq_names[:subset_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gWA_sFM_cAll_d25_mWA4_ch05'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1919, 219)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motion = preprocessing.compute_SMPL_motion(seq_names[0], dataset.motion_dir)\n",
    "motion.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1919, 72)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smpl_poses, smpl_scaling, smpl_trans = AISTDataset.load_motion(dataset.motion_dir, seq_names[0])\n",
    "smpl_trans /= smpl_scaling\n",
    "smpl_poses.shape\n",
    "# 24 rotation vectors. Each is 3D: magnitude is angle, direction is axis, so the vector is an axis-angle rep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotation_6d_to_matrix(d6: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Converts 6D rotation representation by Zhou et al. [1] to rotation matrix\n",
    "    using Gram--Schmidt orthogonalization per Section B of [1].\n",
    "    Args:\n",
    "        d6: 6D rotation representation, of size (*, 6)\n",
    "    Returns:\n",
    "        batch of rotation matrices of size (*, 3, 3)\n",
    "    [1] Zhou, Y., Barnes, C., Lu, J., Yang, J., & Li, H.\n",
    "    On the Continuity of Rotation Representations in Neural Networks.\n",
    "    IEEE Conference on Computer Vision and Pattern Recognition, 2019.\n",
    "    Retrieved from http://arxiv.org/abs/1812.07035\n",
    "    \"\"\"\n",
    "\n",
    "    a1, a2 = d6[..., :3], d6[..., 3:]\n",
    "    b1 = a1 / np.linalg.norm(a1, axis=-1, keepdims=True)\n",
    "    b2 = a2 - (b1 * a2).sum(-1, keepdims=True) * b1\n",
    "    b2 = b2 / np.linalg.norm(b2, axis=-1, keepdims=True)\n",
    "    b3 = np.cross(b1, b2, axis=-1)\n",
    "    return np.stack((b1, b2, b3), axis=-2)\n",
    "\n",
    "\n",
    "def matrix_to_rotation_6d(matrix: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Converts rotation matrices to 6D rotation representation by Zhou et al. [1]\n",
    "    by dropping the last row. Note that 6D representation is not unique.\n",
    "    Args:\n",
    "        matrix: batch of rotation matrices of size (*, 3, 3)\n",
    "    Returns:\n",
    "        6D rotation representation, of size (*, 6)\n",
    "    [1] Zhou, Y., Barnes, C., Lu, J., Yang, J., & Li, H.\n",
    "    On the Continuity of Rotation Representations in Neural Networks.\n",
    "    IEEE Conference on Computer Vision and Pattern Recognition, 2019.\n",
    "    Retrieved from http://arxiv.org/abs/1812.07035\n",
    "    \"\"\"\n",
    "    return np.copy(matrix[..., :2, :]).reshape(*matrix.shape[:-2], 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1919, 24, 6) (1919, 24, 3, 3) (1919, 24, 3, 3) True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 0.84896038,  0.02461495, -0.52788292],\n",
       "        [-0.07640416,  0.99413637, -0.07651979],\n",
       "        [ 0.52290408,  0.10529472,  0.84586308]]),\n",
       " array([[ 0.84896038,  0.02461495, -0.52788292],\n",
       "        [-0.07640416,  0.99413637, -0.07651979],\n",
       "        [ 0.52290408,  0.10529472,  0.84586308]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motion_reshaped = motion[:,3:].reshape((motion.shape[0], -1, 3, 3))\n",
    "motion_6D = matrix_to_rotation_6d(motion_reshaped)\n",
    "motion_rotmat_recovered = rotation_6d_to_matrix(motion_6D)\n",
    "print(motion_6D.shape, motion_rotmat_recovered.shape, motion_reshaped.shape, np.allclose(motion_reshaped, motion_rotmat_recovered))\n",
    "motion_reshaped[0,0,...], motion_rotmat_recovered[0,0,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_compute_SMPL_motion(seq_name: str, motion_dir: str) -> np.ndarray:\n",
    "    smpl_poses, smpl_scaling, smpl_trans = AISTDataset.load_motion(motion_dir, seq_name)\n",
    "    smpl_trans /= smpl_scaling\n",
    "\n",
    "    smpl_poses = R.from_rotvec(smpl_poses.reshape((-1, 3))).as_matrix().reshape((smpl_poses.shape[0], -1, 3, 3))\n",
    "    smpl_poses = matrix_to_rotation_6d(smpl_poses).reshape((smpl_poses.shape[0], -1))\n",
    "\n",
    "    smpl_motion = np.concatenate([smpl_trans, smpl_poses], axis=-1)\n",
    "    return smpl_motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1919, 147)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_motion = new_compute_SMPL_motion(seq_names[0], dataset.motion_dir)\n",
    "new_motion.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_to_old_motion(new_motion: np.ndarray) -> np.ndarray:\n",
    "    trans, rot_6d = new_motion[:, :3], new_motion[:, 3:]\n",
    "    rotmats = rotation_6d_to_matrix(rot_6d.reshape((rot_6d.shape[0], -1, 6)))\n",
    "    rotmats = rotmats.reshape((rot_6d.shape[0], -1))\n",
    "    return np.concatenate([trans, rotmats], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1919, 219)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_motion_recovered = new_to_old_motion(new_motion)\n",
    "old_motion_recovered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.84896038,  0.02461495, -0.52788292],\n",
       "        [-0.07640416,  0.99413637, -0.07651979],\n",
       "        [ 0.52290408,  0.10529472,  0.84586308]]),\n",
       " array([[ 0.95591427,  0.27488122, -0.10328714],\n",
       "        [-0.29360241,  0.8886426 , -0.35229526],\n",
       "        [-0.00505399,  0.36708942,  0.93017193]]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Interpolation\n",
    "i1, i2 = 0, 1\n",
    "m1, m2 = old_motion_recovered[0, 3+9*i1:12+9*i1].reshape((3,3)), old_motion_recovered[0, 3+9*i2:12+9*i2].reshape((3,3))\n",
    "m1, m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.90243732,  0.14974808, -0.31558503],\n",
       "       [-0.18500328,  0.94138949, -0.21440753],\n",
       "       [ 0.25892504,  0.23619207,  0.8880175 ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_half = 0.5 * (m1 + m2)\n",
    "m_half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.84896038,  0.02461495, -0.52788292, -0.07640416,  0.99413637,\n",
       "        -0.07651979]),\n",
       " array([ 0.95591427,  0.27488122, -0.10328714, -0.29360241,  0.8886426 ,\n",
       "        -0.35229526]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n1, n2 = new_motion[0, 3+6*i1:9+6*i1], new_motion[0, 3+6*i2:9+6*i2]\n",
    "n1, n2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.90243732,  0.14974808, -0.31558503, -0.18500328,  0.94138949,\n",
       "       -0.21440753])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_half = 0.5 * (n1 + n2)\n",
    "n_half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.9325748 ,  0.15474901, -0.3261242 ],\n",
       "        [-0.2292721 ,  0.95174307, -0.20400841],\n",
       "        [ 0.27881634,  0.26502428,  0.92305123]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rotation_6d_to_matrix(n_half[None, ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-1.11022302e-16, -2.77555756e-17,  5.55111512e-17],\n",
       "        [ 5.55111512e-17, -2.22044605e-16,  5.55111512e-17],\n",
       "        [-5.55111512e-17,  0.00000000e+00, -2.22044605e-16]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R.from_matrix(rotation_6d_to_matrix(n_half[None, ...])).as_matrix() - rotation_6d_to_matrix(n_half[None, ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03688114, -0.01381917,  0.00061811],\n",
       "       [-0.02198716,  0.01536287,  0.01000625],\n",
       "       [ 0.01463626,  0.02100096,  0.03881364]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R.from_matrix(m_half).as_matrix() - m_half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[ 0.93900494,  0.13519189, -0.31621651],\n",
       "         [-0.20635196,  0.95706335, -0.20358931],\n",
       "         [ 0.27511561,  0.25642326,  0.92658432]]]),\n",
       " array([[ 0.93931846,  0.13592891, -0.31496692],\n",
       "        [-0.20699044,  0.95675236, -0.20440127],\n",
       "        [ 0.2735613 ,  0.25719303,  0.92683114]]),\n",
       " array([[[ 0.9325748 ,  0.15474901, -0.3261242 ],\n",
       "         [-0.2292721 ,  0.95174307, -0.20400841],\n",
       "         [ 0.27881634,  0.26502428,  0.92305123]]]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualize.get_closest_rotmat(m_half[None, ...]), R.from_matrix(m_half).as_matrix(), rotation_6d_to_matrix(n_half[None, ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.00000000e+00, -5.55111512e-17, -5.55111512e-17],\n",
       "        [ 0.00000000e+00,  1.11022302e-16, -8.32667268e-17],\n",
       "        [ 0.00000000e+00,  5.55111512e-17,  1.11022302e-16]]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rotation_6d_to_matrix(n_half[None, ...]) - visualize.get_closest_rotmat(rotation_6d_to_matrix(n_half[None, ...]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "73ef9dae1850d4826a6a2abacc613ceaa38b06453232522e74b0afa9475d9130"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('ai-choreo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
